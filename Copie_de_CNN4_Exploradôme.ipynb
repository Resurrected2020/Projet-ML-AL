{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de CNN4_Explorad√¥me",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Resurrected2020/Projet-ML-AL/blob/master/Copie_de_CNN4_Explorad%C3%B4me.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3mtRM5BY8sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqwbrpBhQVa7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "767d3db9-67e9-4c07-ac0a-63127619f4f1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB7RHmoHm3wn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#Affichage de quelques images du dataset\n",
        "plt.figure(figsize=(100,100))\n",
        "for index, image in enumerate(zip(train_ds[20:40],validation_ds[20:40])):\n",
        "    plt.subplot(20, 40, index + 1)\n",
        "    plt.imshow(image/255)\n",
        "    #plt.title('Training: %i\\n' % label, fontsize = 20)\n",
        "    plt.axis('off');\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wr49_A0Ggvl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "08890823-ec42-4db5-d3b1-65b74a3b4315"
      },
      "source": [
        "import os\n",
        "path=\"/content/drive/My Drive/DATASET FINAL/images_finales/train/\"\n",
        "path2=path\n",
        "dossiers=os.listdir(path)\n",
        "for i in dossiers: \n",
        "  dossiers=os.listdir(path+i)\n",
        "  taille=int(len(dossiers)/250)\n",
        "  liste=list(range(1,taille+1)\n",
        "for j in liste:\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "  '''\n",
        "  for str(i) in liste:\n",
        "    path2=os.path.join(path,i)\n",
        "    os.mkdir(path2)\n",
        "    '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2]\n",
            "[0, 1]\n",
            "[0, 1, 2, 3, 4]\n",
            "[0, 1]\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "[0, 1, 2, 3, 4, 5]\n",
            "[0, 1]\n",
            "[0, 1]\n",
            "[0, 1, 2]\n",
            "[0, 1, 2, 3]\n",
            "[0, 1, 2]\n",
            "[0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUlDekt1SwNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " import os\n",
        "import system\n",
        "path=\"/content/drive/My Drive/DATASET FINAL/images_finales/train/\"\n",
        "path2=path\n",
        "dossiers=os.listdir(path)\n",
        "for i in dossiers: \n",
        "  dossiers=os.listdir(path+i)\n",
        "  taille=int(len(dossiers)/250)\n",
        "  liste=list(range(1,taille+1)\n",
        "for j in liste:\n",
        "# Path to be created\n",
        "path = \n",
        "os.mkdir( path, 0755 );\n",
        "print (\"Path is created\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV9u0C3ct0gZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "import time\n",
        "\n",
        "dossiers=os.listdir(\"/content/drive/My Drive/DATASET FINAL/images_finales/train/\")\n",
        "path=\"/content/drive/My Drive/DATASET FINAL/images_finales/train/\"\n",
        "c=0\n",
        "train_image=[]\n",
        "for i in dossiers:\n",
        "  path2=path+i\n",
        "  images=os.listdir(path2)\n",
        "  \n",
        "  for j in images:\n",
        "    image_path=path2+'/'+j\n",
        "    long=9668\n",
        "    image = load_img(image_path)\n",
        "    array = img_to_array(image)\n",
        "    array=array/255\n",
        "    train_image.append(array)\n",
        "    c+=1\n",
        "    time.sleep(3)\n",
        "    print((c/long)*100,\": Taux d'avancement\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id-kbMI8thjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "import os\n",
        "dossiers=os.listdir(\"/content/drive/My Drive/DATASET FINAL/images_finales/test/\")\n",
        "path=\"/content/drive/My Drive/DATASET FINAL/images_finales/test/\"\n",
        "c=0\n",
        "test_image=[]\n",
        "for i in dossiers:\n",
        "  path2=path+i\n",
        "  images=os.listdir(path2)\n",
        "  for j in images:\n",
        "    image_path=path2+'/'+j\n",
        "    long=4122\n",
        "    image = load_img(image_path)\n",
        "    array = img_to_array(image)\n",
        "    array=array/255\n",
        "    test_image.append(array)\n",
        "    c+=1\n",
        "    print((c/long)*100,\": Taux d'avancement\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELIGqKGnvZzT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "df78786a-2fd3-45f5-fc74-eed8ca44a0ca"
      },
      "source": [
        "image_path=\"/content/drive/My Drive/DATASET FINAL/images_finales/test/1/image2794.jpg\"\n",
        "image = load_img(image_path)\n",
        "array = img_to_array(image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0a54b52d6f8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/My Drive/DATASET FINAL/images_finales/test/1/image2794.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_img' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx1X_Whqnj4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "import os\n",
        "dossiers=os.listdir(\"/content/drive/My Drive/DATASET FINAL/images_finales/test/\")\n",
        "path=\"/content/drive/My Drive/DATASET FINAL/images_finales/test/\"\n",
        "c=0\n",
        "for i in dossiers:\n",
        "  path2=path+i\n",
        "  images=os.listdir(path2)\n",
        "  for j in images:\n",
        "    image_path=path2+'/'+j\n",
        "    long=4122\n",
        "    image = load_img(image_path)\n",
        "    array = img_to_array(image)\n",
        "    array=array/255\n",
        "    c+=1\n",
        "    print(c,'/',long,\"images converties\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBKk7NBnagEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d0adb0bd-b0ce-449b-8f96-b41c12d08500"
      },
      "source": [
        "path=\"/content/drive/My Drive/DATASET FINAL/images_finales/test/\"\n",
        "dossiers=os.listdir(\"/content/drive/My Drive/DATASET FINAL/images_finales/test/\")\n",
        "liste=[]\n",
        "for i in dossiers:\n",
        "  path2=path+i\n",
        "  a=len(os.listdir(path2))\n",
        "  liste.append(a)\n",
        "print(sum(liste))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oGTNwHjaNSo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8930b29b-9c31-423d-eb4b-7cb85a3eabcd"
      },
      "source": [
        "import os \n",
        "list_class=os.listdir(\"/content/drive/My Drive/DATASET FINAL/images_finales/train/\")\n",
        "print(list_class)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfWrwDgzjRyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image = []\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "    img = image.load_img('/content/drive/My Drive/DATASET FINAL/images_finales/train'+train['filename'][i], target_size=(28,28,1), grayscale=True)\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    train_image.append(img) \n",
        "X = np.array(train_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVBdcChdSjrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0cd8762c-f9ab-4312-9e6c-6690fe6dc098"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "\n",
        "training_ds = image_dataset_from_directory(\n",
        "    directory='/content/drive/My Drive/DATASET FINAL/images_finales/train/',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=list_class,\n",
        "    color_mode=\"rgba\",\n",
        "    batch_size=32,\n",
        "    image_size=(256, 256), \n",
        "    shuffle=True,\n",
        "    seed=10)\n",
        "\n",
        "validation_ds = image_dataset_from_directory(\n",
        "    directory='/content/drive/My Drive/DATASET FINAL/images_finales/test/',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=list_class,\n",
        "    color_mode=\"rgba\",\n",
        "    batch_size=32,\n",
        "    image_size=(256, 256),\n",
        "    shuffle=True,\n",
        "    seed=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9668 files belonging to 12 classes.\n",
            "Found 4122 files belonging to 12 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxanpNl8UqOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CNN4 = keras.Sequential()\n",
        "CNN4.add(keras.layers.Conv2D(a, kernel_size=(x,y), activation=b, strides=(c,d)))\n",
        "CNN4.add(keras.layers.MaxPooling2D(2,2))\n",
        "CNN4.add(keras.layers.Conv2D(a, kernel_size=(x,y), activation=b, strides=(c,d)))\n",
        "CNN4.add(keras.layers.MaxPooling2D(2,2))\n",
        "CNN4.add(keras.layers.Dropout(0.25))\n",
        "CNN4.add(keras.layers.Flatten())\n",
        "CNN4.add(keras.layers.Dense(64, activation=b))\n",
        "CNN4.add(keras.layers.Dense(12, activation='softmax'))\n",
        "\n",
        "\n",
        "CNN4.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss='categorical_crossentropy',metrics = 'accuracy')\n",
        " \n",
        "CNN4.fit(training_ds, validation_ds, epochs=10, batch_size=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTHbY7vUSg7b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "cfc528af-d151-46ab-feb3-b8e6e654451f"
      },
      "source": [
        "CNN4 = keras.Sequential()\n",
        "CNN4.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', strides=(1,1)))\n",
        "CNN4.add(keras.layers.MaxPooling2D(2,2))\n",
        "CNN4.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', strides=(1,1)))\n",
        "CNN4.add(keras.layers.MaxPooling2D(2,2))\n",
        "CNN4.add(keras.layers.Dropout(0.25))\n",
        "CNN4.add(keras.layers.Flatten())\n",
        "CNN4.add(keras.layers.Dense(64, activation='relu'))\n",
        "CNN4.add(keras.layers.Dense(12, activation='softmax'))\n",
        "\n",
        "\n",
        "CNN4.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss='categorical_crossentropy',metrics = 'accuracy')\n",
        " \n",
        "CNN4.fit(x_rain, validation_ds, epochs=10, batch_size=100)\n",
        "\n",
        "\n",
        "print(\"Test evaluation\")\n",
        "CNN4.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b82a4f952443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mCNN4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mCNN4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, steps, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_user_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_validate_args\u001b[0;34m(self, y, sample_weights, steps)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;31m# Arguments that shouldn't be passed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m       raise ValueError(\"`y` argument is not supported when using \"\n\u001b[0m\u001b[1;32m    734\u001b[0m                        \"dataset as input.\")\n\u001b[1;32m    735\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: `y` argument is not supported when using dataset as input."
          ]
        }
      ]
    }
  ]
}